# Use CUDA 11.8 base image for RTX 4090 compatibility
FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=$PATH:$CUDA_HOME/bin
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_HOME/lib64

# Install system dependencies
RUN apt-get update && \
    apt-get install -y \
    git \
    wget \
    curl \
    python3.12 \
    python3.12-venv \
    python3-pip \
    python3.12-dev \
    build-essential \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgthread-2.0-0 \
    ffmpeg \
    openssh-server \
    nodejs \
    npm \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# CUDA toolkit and cuDNN already included in nvidia/cuda base image

# Configure SSH for root login
RUN sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config && \
    sed -i 's/#PasswordAuthentication yes/PasswordAuthentication yes/' /etc/ssh/sshd_config && \
    mkdir -p /run/sshd && \
    rm -f /etc/ssh/ssh_host_*

# Set Python 3.12 as default system-wide
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1 && \
    update-alternatives --set python3 /usr/bin/python3.12

# Create virtual environment for Python packages
RUN python3.12 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Install PyTorch with CUDA 11.8 (compatible with RTX 4090)
RUN pip install --no-cache-dir torch torchvision --index-url https://download.pytorch.org/whl/cu118 && \
    pip cache purge

# Install ComfyUI 0.13.0 (latest stable)
WORKDIR /ComfyUI
RUN git clone https://github.com/comfyanonymous/ComfyUI.git . && \
    git checkout v0.13.0 && \
    pip install --no-cache-dir -r requirements.txt && \
    pip install --no-cache-dir GitPython opencv-python && \
    pip cache purge

# Install llama-cpp-python for GGUF support (CUDA 11.8 compatible with RTX 4090)
RUN CMAKE_ARGS="-DGGML_CUDA=on" pip install --upgrade --force-reinstall --no-cache-dir \
    "llama-cpp-python @ git+https://github.com/JamePeng/llama-cpp-python.git" && \
    pip cache purge

# Install ALL ComfyUI custom nodes from VastAI provisioning + RunpodDirect
RUN cd /ComfyUI/custom_nodes && \
    git clone https://github.com/ltdrdata/ComfyUI-Manager.git && \
    git clone https://github.com/cubiq/ComfyUI_essentials.git && \
    git clone https://github.com/huchukato/comfy-tagcomplete.git && \
    git clone https://github.com/huchukato/ComfyUI-QwenVL-Mod.git && \
    git clone https://github.com/huchukato/ComfyUI-RIFE-TensorRT-Auto.git && \
    git clone https://github.com/MadiatorLabs/ComfyUI-RunpodDirect.git && \
    git clone https://github.com/city96/ComfyUI-GGUF.git && \
    git clone https://github.com/ltdrdata/ComfyUI-Impact-Pack.git && \
    git clone https://github.com/MoonGoblinDev/Civicomfy.git && \
    git clone https://github.com/Koishi-Star/Euler-Smea-Dyn-Sampler.git && \
    git clone https://github.com/ltdrdata/was-node-suite-comfyui.git && \
    git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git && \
    git clone https://github.com/rgthree/rgthree-comfy.git && \
    git clone https://github.com/yolain/ComfyUI-Easy-Use.git && \
    git clone https://github.com/kijai/ComfyUI-KJNodes.git && \
    git clone https://github.com/Fannovel16/ComfyUI-Frame-Interpolation.git && \
    git clone https://github.com/Smirnov75/ComfyUI-mxToolkit.git && \
    git clone https://github.com/princepainter/ComfyUI-PainterI2V.git && \
    git clone https://github.com/princepainter/ComfyUI-PainterI2Vadvanced.git && \
    git clone https://github.com/princepainter/ComfyUI-PainterLongVideo.git && \
    git clone https://github.com/ashtar1984/comfyui-find-perfect-resolution.git && \
    git clone https://github.com/ComfyAssets/ComfyUI_Selectors.git && \
    git clone https://github.com/kijai/ComfyUI-MMAudio.git && \
    git clone https://github.com/GACLove/ComfyUI-VFI.git && \
    git clone https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt.git && \
    git clone https://github.com/stduhpf/ComfyUI-WanMoeKSampler.git && \
    git clone https://github.com/melMass/comfy_mtb.git

# Install requirements for all custom nodes
RUN cd /ComfyUI/custom_nodes && \
    for node_dir in */; do \
        if [ -f "$node_dir/requirements.txt" ]; then \
            echo "Installing requirements for $node_dir..." && \
            pip install --no-cache-dir -r "$node_dir/requirements.txt" || echo "Failed to install requirements for $node_dir"; \
        fi; \
    done && \
    pip cache purge

# ComfyUI-Easy-Use-Frontend removed due to compatibility issues

# Install additional essential dependencies
RUN pip install --no-cache-dir sageattention torchsde triton opencv-python-headless scikit-image spandrel safetensors jupyterlab huggingface_hub && \
    pip cache purge

# Install web terminal (wetty) with fallback
RUN npm install -g wetty || \
    (npm cache clean --force && \
     npm install -g n && \
     n latest && \
     npm install -g wetty) || \
    echo "âš ï¸ wetty installation failed, will install manually"

# Create web terminal startup script
RUN echo '#!/bin/bash\n\
wetty --port 8081 --command bash &' > /start-terminal.sh && \
    chmod +x /start-terminal.sh

# HuggingFace login for private models (if token provided)
RUN if [ -n "$HF_TOKEN" ]; then \
    echo "ðŸ”‘ Logging into HuggingFace..." && \
    huggingface-cli login --token $HF_TOKEN; \
    fi

# Clean up heavy Git files to save space (keep repo structure for updates)
RUN find /ComfyUI/custom_nodes -name ".git" -type d -exec find {} -name "*.pack" -delete + || true && \
    find /ComfyUI/custom_nodes -name ".git" -type d -exec find {} -name "pack-*.idx" -delete + || true && \
    find /ComfyUI/custom_nodes -name ".git" -type d -exec find {} -name "objects" -type d -exec rm -rf {} + || true

# Aggressive cleanup to reduce image size
RUN rm -rf /tmp/* \
       && rm -rf /var/lib/apt/lists/* \
       && rm -rf /var/cache/apt/archives/* \
       && find /opt/venv -name "*.pyc" -delete \
       && find /opt/venv -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true \
       && find /ComfyUI -name "*.pyc" -delete \
       && find /ComfyUI -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true

# Set ComfyUI arguments (CUDA 11.8 optimized for RTX 4090)
ENV COMFYUI_ARGS="--disable-auto-launch --listen 0.0.0.0 --port 8188 --enable-cors-header --fast fp16_accumulation --use-sage-attention --reserve-vram 2 --cuda-malloc --async-offload"

# Create startup script (RunPod style with dynamic workflow updates)
RUN echo '#!/bin/bash\n\
set -e  # Exit the script if any statement returns a non-true return value\n\
\n\
COMFYUI_DIR="/ComfyUI"\n\
FILEBROWSER_CONFIG="/filebrowser/.config.json"\n\
DB_FILE="/filebrowser/database/filebrowser.db"\n\
\n\
# Function to download latest workflows\n\
update_workflows() {\n\
    echo "ðŸ”„ Updating workflows from latest versions..."\n\
    cd /ComfyUI/user/default/workflows\n\
    \n\
    # List of latest workflows\n\
    workflows=(\n\
        "PMP-LoRaStack-Upscale-Wildcards.json"\n\
        "WAN2.2-I2V-AutoPrompt-Story.json"\n\
        "WAN2.2-T2V-AutoPrompt-Story.json"\n\
        "Wan2.2-I2V-SVI-AutoPrompt-Story.json"\n\
        "WAN2.2-I2V-AutoPrompt-1-5.json"\n\
        "WAN2.2-I2V-AutoPrompt-GGUF-1-5.json"\n\
        "WAN2.2-T2V-AutoPrompt-1-6.json"\n\
        "WAN2.2-T2V-AutoPrompt-GGUF-1-5.json"\n\
        "Wan2.2-I2V-SVI-AutoPrompt-1-4.json"\n\
        "Wan2.2-I2V-SVI-AutoPrompt-GGUF-1-2.json"\n\
        "WAN2.2-I2V-Full-AutoPrompt-MMAudio-v1-9.json"\n\
        "WAN2.2-I2V-Full-AutoPrompt-MMAudio-GGUF-v1-6.json"\n\
        "WAN2.2-T2V-Full-AutoPrompt-MMAudio-GGUF-1-1.json"\n\
    )\n\
    \n\
    for workflow in "${workflows[@]}"; do\n\
        echo "  ðŸ“¥ Downloading: $workflow"\n\
        wget -q "https://github.com/huchukato/ComfyUI-QwenVL-Mod/raw/main/vastai/workflows/$workflow" -O "$workflow" || echo "  âš ï¸ Failed to download $workflow"\n\
    done\n\
    \n\
    echo "âœ… Workflow update completed"\n\
}\n\
\n\
download_models() {\n\
    echo "ðŸ”„ Downloading essential models..."\n\
    cd /ComfyUI\n\
    \n\
    # Download VAE models\n\
    if [ ! -f "/ComfyUI/models/vae/wan_2.1_vae.safetensors" ]; then\n\
        echo "  ðŸ“¥ Downloading WAN 2.1 VAE..."\n\
        wget -q "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors" -O "/ComfyUI/models/vae/wan_2.1_vae.safetensors" || echo "  âš ï¸ Failed to download VAE"\n\
    fi\n\
    \n\
    if [ ! -f "/ComfyUI/models/vae/Wan2_1_VAE_fp32.safetensors" ]; then\n\
        echo "  ðŸ“¥ Downloading WAN 2.1 VAE fp32..."\n\
        wget -q "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/Wan2_1_VAE_fp32.safetensors" -O "/ComfyUI/models/vae/Wan2_1_VAE_fp32.safetensors" || echo "  âš ï¸ Failed to download fp32 VAE"\n\
    fi\n\
    \n\
    if [ ! -f "/ComfyUI/models/vae/sdxl.vae.safetensors" ]; then\n\
        echo "  ðŸ“¥ Downloading SDXL VAE..."\n\
        wget -q "https://huggingface.co/huchukato/favs/resolve/main/VAE/sdxl.vae.safetensors" -O "/ComfyUI/models/vae/sdxl.vae.safetensors" || echo "  âš ï¸ Failed to download SDXL VAE"\n\
    fi\n\
    \n\
    # Download upscale models\n\
    if [ ! -f "/ComfyUI/models/upscale_models/2xLexicaRRDBNet.pth" ]; then\n\
        echo "  ðŸ“¥ Downloading 2xLexicaRRDBNet upscale model..."\n\
        wget -q "https://huggingface.co/huchukato/favs/resolve/main/ESRGAN/2xLexicaRRDBNet.pth" -O "/ComfyUI/models/upscale_models/2xLexicaRRDBNet.pth" || echo "  âš ï¸ Failed to download upscale model"\n\
    fi\n\
    \n\
    if [ ! -f "/ComfyUI/models/upscale_models/2xLexicaRRDBNet_Sharp.pth" ]; then\n\
        echo "  ðŸ“¥ Downloading 2xLexicaRRDBNet Sharp upscale model..."\n\
        wget -q "https://huggingface.co/huchukato/favs/resolve/main/ESRGAN/2xLexicaRRDBNet_Sharp.pth" -O "/ComfyUI/models/upscale_models/2xLexicaRRDBNet_Sharp.pth" || echo "  âš ï¸ Failed to download Sharp upscale model"\n\
    fi\n\
    \n\
    # Download text encoder\n\
    if [ ! -f "/ComfyUI/models/text_encoders/nsfw_wan_umt5-xxl_fp8_scaled.safetensors" ]; then\n\
        echo "  ðŸ“¥ Downloading NSFW WAN UMT5-XXL text encoder..."\n\
        wget -q "https://huggingface.co/NSFW-API/NSFW-Wan-UMT5-XXL/resolve/main/nsfw_wan_umt5-xxl_fp8_scaled.safetensors" -O "/ComfyUI/models/text_encoders/nsfw_wan_umt5-xxl_fp8_scaled.safetensors" || echo "  âš ï¸ Failed to download text encoder"\n\
    fi\n\
    \n\
    echo "âœ… Model download completed"\n\
    echo "ðŸ“‹ Available models:"\n\
    ls -la /ComfyUI/models/vae/\n\
    ls -la /ComfyUI/models/upscale_models/\n\
    ls -la /ComfyUI/models/text_encoders/\n\
}\n\
\n\
echo "ðŸš€ Starting ComfyUI-QwenVL-Mod on RunPod (RTX 4090 Version)"\n\
echo "ðŸŽ¬ WAN 2.2 workflows ready"\n\
echo "ðŸŒ Multilingual support enabled"\n\
echo "ðŸŽ¨ Visual style detection ready"\n\
echo "âš¡ GGUF backend optimized"\n\
echo "ðŸ”¥ CUDA 11.8 optimized for RTX 4090"\n\
echo ""\n\
\n\
# Update workflows to latest versions\n\
update_workflows\n\
\n\
# Download essential models\n\
download_models\n\
\n\
echo "ðŸ”§ Services starting:"\n\
echo "ðŸ“ FileBrowser: http://0.0.0.0:8080"\n\
echo "ðŸ““ JupyterLab:  http://0.0.0.0:8888"\n\
echo "ðŸ–¥ï¸ WebTerminal: http://0.0.0.0:8081"\n\
echo "ðŸŽ¨ ComfyUI:    http://0.0.0.0:8188"\n\
echo "ðŸ“‹ Available workflows:"\n\
ls -la /ComfyUI/user/default/workflows/\n\
echo ""\n\
echo "ðŸ’¡ Models pre-loaded for immediate use"\n\
echo ""\n\
\n\
# Start FileBrowser\n\
echo "ðŸ”§ Starting FileBrowser..."\n\
nohup /usr/local/bin/start-filebrowser.sh &> /filebrowser.log &\n\
echo "âœ… FileBrowser started"\n\
\n\
# Start JupyterLab\n\
echo "ðŸ”§ Starting JupyterLab..."\n\
nohup /usr/local/bin/start-jupyter.sh &> /jupyter.log &\n\
echo "âœ… JupyterLab started"\n\
\n\
# Start Web Terminal\n\
echo "ðŸ–¥ï¸ Starting Web Terminal..."\n\
nohup /start-terminal.sh &> /terminal.log &\n\
echo "âœ… Web Terminal started on port 8081"\n\
\n\
# Start ComfyUI\n\
echo "ðŸš€ Starting ComfyUI..."\n\
echo "ðŸŒ ComfyUI will be available at: http://0.0.0.0:8188"\n\
echo "ðŸ–¥ï¸ Web Terminal: http://0.0.0.0:8081"\n\
cd $COMFYUI_DIR\n\
nohup python main.py --disable-auto-launch --listen 0.0.0.0 --port 8188 --enable-cors-header --fast fp16_accumulation --use-sage-attention --reserve-vram 2 --cuda-malloc --async-offload &> /comfyui.log &\n\
echo "âœ… ComfyUI started"\n\
\n\
# Tail the ComfyUI log\n\
tail -f /comfyui.log\n\
' > /ComfyUI/start.sh && chmod +x /ComfyUI/start.sh

# Create user directory structure
RUN mkdir -p /ComfyUI/user/default/workflows

# Create models directories
RUN mkdir -p /ComfyUI/models/vae && \
    mkdir -p /ComfyUI/models/upscale_models && \
    mkdir -p /ComfyUI/models/text_encoders

# Set working directory
WORKDIR /ComfyUI

# Expose ports
EXPOSE 8080 8188 8888 8081

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://0.0.0.0:8188/system_stats || exit 1

# Start ComfyUI
CMD ["/ComfyUI/start.sh"]
